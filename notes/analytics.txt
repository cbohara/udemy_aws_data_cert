#####
Kinesis analytics
#####
not only accepts input from kinesis data stream
also accepts input from kinesis firehose

can also include reference source table to enrich your input data stream
store reference data as an object in S3
creates in-app table for lookups

application code = SQL statements 
operates over windows of time

destination > kinesis data stream or firehose
any errors that occur will be sent to kinesis error stream

use cases for Kinesis Analytics
1. realtime ETL
2. continuous metric generation
ex: calculate # of uniq website visitors every 5 minutes
send results to Redshift for further analysis 
3. responsive analytics 
ex: monitor for events that mean certain criteria + then automatically notify the right customers > output to kinesis stream > notify via SNS

cost
use carefully bc it isn't cheap

security
enabled via iam permissions

schema discovery 
analyzes incoming data from your stream
edit + correct as needed

RANDOM_CUT_FOREST
SQL function
used for anomaly detection on numeric columns in a stream
novel way to identify outliers in a data set

https://docs.aws.amazon.com/kinesisanalytics/latest/dev/how-it-works-app-code.html
when you select rows, you insert results into another in-application stream
use pumps to write to an in-application stream

#####
AWS Elasticsearch Service
#####
petabyte scale analysis and reporting
horizontally scalable
performant and cheap

elasticsearch is a search engine
built on top of open source version of Lucine
part of the elastic stack

includes Beats/LogStash - allows you to import data at scale into ElasticSearch cluster
can use Kibana to visualize the data - like a Google Analytics dashboard

use cases
full-text search
log analytics
application monitoring
security analytics
clickstream analytics

ElasticSearch concepts
documents - things you are looking for
can be more than text - any structured JSON data works
every document has a unique ID

types - define schema + mapping shared by documents that represent the same sort of thing
going to be deprecated and replaced with indices

indices - power search into all documents within a collection of types
contain inverted indices that let you search across everything within them at one
essentially a collection of documents that are related to some thing

indices are split into shards
each shard exists in a different node in a cluster
each shard is its own mini search engine

each index has 2 primary shards + 2 replicas
write requests are routed to the primary shard, then replicated
read requests are routed to the primary or any replica
your application is responsiblef for round-robin the read requests amongst the nodes

Amazon ElasticSearch service
fully-managed but not serverless
you need to chose the number of nodes like EMR
pay for what you use - instance hours, storage, and data transfer
network isolation using VPC
security with encryption at rest + in transit
control access via cognito and IAM

integration with other AWS services
itegrates well with IoT
offers node awareness - can have 2 AZ in same region = increase availability but increase latency
can use kinesis > lambda > elasticsearch
can also receieve dynamoDB streams

setup options
how many dedicated master nodes do you want? 
domains aka cluster
snapshots to S3? good for automated backup storage
zone awareness? increase availability but also increase latency 

ES Security
request signing required for all incoming traffic
can setup cluster in the VPC but cannot change later

if you setup ES cluster in a VPC, how do you access Kibana (which is a web interface)?
easiest way to do so is to use Cognito for login > access Kibana
if working on public you can update access policy to specify your IP address

ES antipatterns
shouldn't be used for OLTP (no transaction support)
encouraged for search + analytics but not necessarily ad-hoc querying
AWS encourages you to use AWS for that

######
Athena
######
ORC and Parquet are columnar and splittable
Avro is splittable but more for row based storage

use cases
good for ad-hoc querying
can checkout data before loading into Redshift data warehouse
analyze logs 
integration with Jupyter/Zeppelin
integration with QuickSight or via ODBC/JDBC with other viz tools

Athena + Glue
Glue stores metadata about S3 dataset
expose table definition to Athena

Athena cost model
$5/TB scanned for successful or cancelled queries
not charged for failed queries
no charge for DDL (create/alter/drop)
better cost + performance with ORC and Parquet
partitioning data reduces cost > scan less data

security
can encrypt Athena results using SSE-SE, SSE-KMS, or CSE-KMS
transport layer security (TLS) encrypts in-transit between Athena and S3

