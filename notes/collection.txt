##########
collection
##########

##########
overview
##########
move data into AWS

real time > immediate action
# kinesis data streams
# SQS
# IoT

near-real time > reactive action
# kinesis firehose
# DMS

batch = historical analysis
# Snowball
# Data pipeline

##########
kinesis streams
##########
managed alternative to Kafka
great for real-time big data
data is automatically replicated syncronously in 3 AZ

streams - low latency to ingest at scale
made up of shards/partitions
producer > stream containing many shards > consumer
default only stores 24 hours but can retain up to 7 days
can reprocess/replay data as long as it is available in the stream 
so multiple applications can be reading from the same stream
it is an append only data store - the data within kinesis stream is immutable

shards
one stream is made of many shards
billed per shard
# of shards per stream can change (reshard or merge)
records are ordered per shard based on when they are received 

records contain
1. data blob
up to 1 MB
serialized as bytes so contain whatever you want

2. record key
sent along with the data blob
provided by producer
helps group records in shards
same key = same shard
use highly distributed key to avoid hot partition problem

3. sequence number 
added by kinesis, not by the producer
unique ID for each record in the shard

producer limits
1 MB or 1000 messages/sec at write per shard
if you exceed this then you will receive a ProvisionedThoroughputException error

consumer classic
2MB/second per shard across all the consumers
OR 
5 API calls per second per shard across all the consumers

consumer enhanced fan out
2MB/second per read per shard per enhanced consumer
No API calls needed - uses a push model 
better scaling

data retention
24 hours by default
can extend to 7 days

########
kinesis producers
########
kinesis SDK - can use boto library
kinesis producer library (KPL) - more advanced, better code, enhanced thoroughput
kinesis agent - linux program that runs on servers - allows you to get log file + send to kinesis stream
third party libraries - spark

kinesis SDK
PutRecord or PutRecords 
PutRecords uses batching = better thoroughput
but have to be careful to avoid ProvisionedThoroughputExceeded error 
use cases - lower thoroughput, higher latency, simple API, AWS lambda

managed services for kinesis data streams 
use SDK behind the scenes
include CloudWatch Logs, AWS IoT, and Kinesis Data Analytics

ProvisionedThoroughputException
exceeding # of MB/second or records/second for any shard
need to avoid a hot partition
need to distribute as much as possible to avoid hot partition
solution
1. add retries with backoffs
2. increase # of shards
3. ensure you have a good partition key
ex: instead of using ios or android as a key, use the device ID

kinesis KPL
C++/Java library
high performance, long-running producers
automated and configurable retry mechanism built in
synchronous (same as SDK) or asynchronous (better performance) API
compression is not available out of the box
submits metrics to CloudWatch for monitoring
*supports batching*
aggregate a bunch of tiny records up to 1 MB and then post to kinesis stream as 1 API call
we can influence batching efficiency by introducing some delay with RecordMaxBufferedTime (default 100ms) so some latentecy with the tradeoff of being more efficient

kinesis agent
install on Linux-based server environments only
monitor log files + send to kinesis data streams
built on top of the KPL
you can even preprocess data before sending to stream
emit metrics to CloudWatch for monitoring

#####
kinesis consumers
#####
Kinesis SDK (boto3)/CLI
Kinesis Client Library (KCL)
Kinesis Connector Library
3rd party libraries - Spark
Kinesis Firehose
Lambda

GetRecords
Consumer SDK - GetRecords
Classic 
records are polled by consumers from the shard
polling because the consumer makes a GetRecords() request and then ingests the data
each shard has 2MB total aggregate throughput per second
however can return a total of up to 10 MB of data
if 10MB is rturned then you have to wait 5 seconds before the next call 
or you can pull upto 10,000 records 

max 5 GetRecords API calls per shard per second
200ms latency

if 5 consumer applications consume from the same shard, then each consumer can poll once per second and receive less than 400 KB/second
all consumers share the same limit of 2MB per shard and 5 GetRecords API calls per second

Kinesis Client Library (KCL)
Java First, but exists for Python
Read records produced by KPL and performs de-aggregation

know that the kinsis connector library exists
although it is pretty much deprecated now

lambda consumer
has a library to take care of de-aggregating records from the kinesis producer library
used to run lightweight ETL 
Lambda has a configurable batch size to manage thoroughput
